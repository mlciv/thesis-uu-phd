@article{tsochantaridis2005large,
  title={Large margin methods for structured and interdependent output variables.},
  author={Tsochantaridis, Ioannis and Joachims, Thorsten and Hofmann, Thomas and Altun, Yasemin and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={6},
  number={9},
  year={2005}
}

@article{koller2004max,
  title={Max-margin Markov networks},
  author={Koller, Ben Taskar Carlos Guestrin Daphne},
  journal={Advances in neural information processing systems},
  volume={16},
  pages={25},
  year={2004}
}

@article{tu2018learning,
  title={Learning approximate inference networks for structured prediction},
  author={Tu, Lifu and Gimpel, Kevin},
  journal={ICLR},
  year={2018}
}

@article{smith2011linguistic,
  title={Linguistic structure prediction},
  author={Smith, Noah A},
  journal={Synthesis lectures on human language technologies},
  volume={4},
  number={2},
  pages={1--274},
  year={2011},
  publisher={Morgan \& Claypool Publishers}
}

@inproceedings{moosavi-strube-2018-using,
    title = "Using Linguistic Features to Improve the Generalization Capability of Neural Coreference Resolvers",
    author = "Moosavi, Nafise Sadat  and
      Strube, Michael",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1018",
    doi = "10.18653/v1/D18-1018",
    pages = "193--203",
    abstract = "Coreference resolution is an intermediate step for text understanding. It is used in tasks and domains for which we do not necessarily have coreference annotated corpora. Therefore, generalization is of special importance for coreference resolution. However, while recent coreference resolvers have notable improvements on the CoNLL dataset, they struggle to generalize properly to new domains or datasets. In this paper, we investigate the role of linguistic features in building more generalizable coreference resolvers. We show that generalization improves only slightly by merely using a set of additional linguistic features. However, employing features and subsets of their values that are informative for coreference resolution, considerably improves generalization. Thanks to better generalization, our system achieves state-of-the-art results in out-of-domain evaluations, e.g., on WikiCoref, our system, which is trained on CoNLL, achieves on-par performance with a system designed for this dataset.",
}

@inproceedings{strubell-etal-2018-linguistically,
    title = "Linguistically-Informed Self-Attention for Semantic Role Labeling",
    author = "Strubell, Emma  and
      Verga, Patrick  and
      Andor, Daniel  and
      Weiss, David  and
      McCallum, Andrew",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1548",
    doi = "10.18653/v1/D18-1548",
    pages = "5027--5038",
    abstract = "Current state-of-the-art semantic role labeling (SRL) uses a deep neural network with no explicit linguistic features. However, prior work has shown that gold syntax trees can dramatically improve SRL decoding, suggesting the possibility of increased accuracy from explicit modeling of syntax. In this work, we present linguistically-informed self-attention (LISA): a neural network model that combines multi-head self-attention with multi-task learning across dependency parsing, part-of-speech tagging, predicate detection and SRL. Unlike previous models which require significant pre-processing to prepare linguistic features, LISA can incorporate syntax using merely raw tokens as input, encoding the sequence only once to simultaneously perform parsing, predicate detection and role labeling for all predicates. Syntax is incorporated by training one attention head to attend to syntactic parents for each token. Moreover, if a high-quality syntactic parse is already available, it can be beneficially injected at test time without re-training our SRL model. In experiments on CoNLL-2005 SRL, LISA achieves new state-of-the-art performance for a model using predicted predicates and standard word embeddings, attaining 2.5 F1 absolute higher than the previous state-of-the-art on newswire and more than 3.5 F1 on out-of-domain data, nearly 10{\%} reduction in error. On ConLL-2012 English SRL we also show an improvement of more than 2.5 F1. LISA also out-performs the state-of-the-art with contextually-encoded (ELMo) word representations, by nearly 1.0 F1 on news and more than 2.0 F1 on out-of-domain text.",
}

@inproceedings{bowman-etal-2016-fast,
    title = "A Fast Unified Model for Parsing and Sentence Understanding",
    author = "Bowman, Samuel R.  and
      Gauthier, Jon  and
      Rastogi, Abhinav  and
      Gupta, Raghav  and
      Manning, Christopher D.  and
      Potts, Christopher",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1139",
    doi = "10.18653/v1/P16-1139",
    pages = "1466--1477",
}


@inproceedings{hovy2010s,
  title={What’s in a preposition? Dimensions of sense disambiguation for an interesting word class},
  author={Hovy, Dirk and Tratz, Stephen and Hovy, Eduard},
  booktitle={Coling 2010: Posters},
  pages={454--462},
  year={2010}
}

@article{punyakanok2008importance,
  title={The importance of syntactic parsing and inference in semantic role labeling},
  author={Punyakanok, Vasin and Roth, Dan and Yih, Wen-tau},
  journal={Computational Linguistics},
  volume={34},
  number={2},
  pages={257--287},
  year={2008},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{xue2004calibrating,
  title={Calibrating features for semantic role labeling.},
  author={Xue, Nianwen and Palmer, Martha},
  booktitle={EMNLP},
  pages={88--94},
  year={2004}
}

@article{werner2014power,
  title={The power of lp relaxation for map inference},
  author={Werner, Tom{\'a}ˇs and Pruˇsa, Daniel},
  journal={Advanced Structured Prediction},
  pages={19},
  year={2014},
  publisher={MIT Press}
}

@inproceedings{finkel2005incorporating,
  title={Incorporating non-local information into information extraction systems by gibbs sampling},
  author={Finkel, Jenny Rose and Grenager, Trond and Manning, Christopher D},
  booktitle={Proceedings of the 43rd annual meeting of the association for computational linguistics (ACL’05)},
  pages={363--370},
  year={2005}
}

@inproceedings{singh2012monte,
  title={Monte Carlo MCMC: efficient inference by approximate sampling},
  author={Singh, Sameer and Wick, Michael and McCallum, Andrew},
  booktitle={Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},
  pages={1104--1113},
  year={2012}
}

@inproceedings{roth2005integer,
  title={Integer linear programming inference for conditional random fields},
  author={Roth, Dan and Yih, Wen-tau},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={736--743},
  year={2005}
}

@inproceedings{berant2014modeling,
  title={Modeling biological processes for reading comprehension},
  author={Berant, Jonathan and Srikumar, Vivek and Chen, Pei-Chun and Vander Linden, Abby and Harding, Brittany and Huang, Brad and Clark, Peter and Manning, Christopher D},
  booktitle={Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={1499--1510},
  year={2014}
}

@article{daume2009search,
  title={Search-based structured prediction},
  author={Daum{\'e}, Hal and Langford, John and Marcu, Daniel},
  journal={Machine learning},
  volume={75},
  number={3},
  pages={297--325},
  year={2009},
  publisher={Springer}
}

@inproceedings{chang2015learning,
  title={Learning to search better than your teacher},
  author={Chang, Kai-Wei and Krishnamurthy, Akshay and Agarwal, Alekh and Daum{\'e} III, Hal and Langford, John},
  booktitle={International Conference on Machine Learning},
  pages={2058--2066},
  year={2015},
  organization={PMLR}
}

@article{rush2012tutorial,
  title={A tutorial on dual decomposition and lagrangian relaxation for inference in natural language processing},
  author={Rush, Alexander M and Collins, MJ},
  journal={Journal of Artificial Intelligence Research},
  volume={45},
  pages={305--362},
  year={2012}
}

@book{cocke1969programming,
  title={Programming languages and their compilers: Preliminary notes},
  author={Cocke, John},
  year={1969},
  publisher={New York University}
}

@article{liu2018learning,
  title={Learning structured text representations},
  author={Liu, Yang and Lapata, Mirella},
  journal={Transactions of the Association for Computational Linguistics},
  volume={6},
  pages={63--75},
  year={2018},
  publisher={MIT Press}
}

@inproceedings{koo-etal-2007-structured,
    title = "Structured Prediction Models via the Matrix-Tree Theorem",
    author = "Koo, Terry  and
      Globerson, Amir  and
      Carreras, Xavier  and
      Collins, Michael",
    booktitle = "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL})",
    month = jun,
    year = "2007",
    address = "Prague, Czech Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D07-1015",
    pages = "141--150",
}

@inproceedings{smith2005contrastive,
  title={Contrastive estimation: Training log-linear models on unlabeled data},
  author={Smith, Noah A and Eisner, Jason},
  booktitle={Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05)},
  pages={354--362},
  year={2005}
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}