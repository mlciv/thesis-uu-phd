\contentsline {table}{\numberline {3.1}{\ignorespaces Detailed classifiers in our model, round bracket means the number of ouput classes of our classify, * means copy mechanism is used in our classifier. At the end of shared task, EDS are not fully supported to get an official results, we leave it as our future work.\relax }}{13}{table.caption.7}
\contentsline {table}{\numberline {3.2}{\ignorespaces Official results overview on unified MRP metric, we selected the performance from top 1/3/5 system(s) for comparison\relax }}{15}{table.caption.8}
\contentsline {table}{\numberline {3.3}{\ignorespaces Official results overview on unified MRP metric, we selected the performance from top 1/3/5 system(s) for comparison. It shows our UCCA model for post-evluation can rank 5th\relax }}{16}{table.caption.9}
\contentsline {table}{\numberline {3.4}{\ignorespaces Our parser on AMR ranked 1st. This table shows the error breakdown when comparing to the baseline TUPA model and top 2\nobreakspace {}\cite {Che:Dou:Xu:19} in official results\relax }}{16}{table.caption.10}
\contentsline {table}{\numberline {3.5}{\ignorespaces Our parser on DM ranked 7th. This table shows the error breakdown when comparing to the model ranked Top 1\nobreakspace {}\cite {Li:Zha:Zha:19} in official results\relax }}{16}{table.caption.11}
\contentsline {table}{\numberline {3.6}{\ignorespaces Our parser on PSD ranked 6th. This table shows the error breakdown when comparing to the model ranked top 1\nobreakspace {}\cite {Don:Fow:Gro:19} in official results\relax }}{17}{table.caption.12}
\contentsline {table}{\numberline {3.7}{\ignorespaces Our UCCA parser in post-evaluation ranked 5th according to the original official evaluation results. This table shows the error breakdown when comparing to the model ranked top 1\nobreakspace {}\cite {Che:Dou:Xu:19} in official results. * denotes the ranking of post-evaluation results \relax }}{18}{table.caption.13}
\contentsline {table}{\numberline {4.1}{\ignorespaces Detailed classifiers in our model, round bracket means the number of ouput classes of our classify, * means copy mechanism is used in our classifier. At the end of shared task, EDS are not fully supported to get an official results, we leave it as our future work.\relax }}{23}{table.caption.15}
\contentsline {table}{\numberline {4.2}{\ignorespaces Official results overview on unified MRP metric, we selected the performance from top 1/3/5 system(s) for comparison. It shows our UCCA model for post-evluation can rank 5th\relax }}{23}{table.caption.16}
\contentsline {table}{\numberline {4.3}{\ignorespaces Our UCCA parser in post-evaluation ranked 5th according to the original official evaluation results. This table shows the error breakdown when comparing to the model ranked top 1\nobreakspace {}\cite {Che:Dou:Xu:19} in official results. * denotes the ranking of post-evaluation results \relax }}{24}{table.caption.17}
\contentsline {table}{\numberline {5.1}{\ignorespaces An example of ongoing therapy session\relax }}{26}{table.caption.18}
\contentsline {table}{\numberline {5.2}{\ignorespaces Summary of word attention mechanisms. We simplify BiDAF with multiplicative attention between word pairs for $f_{m}$, while GMGRU uses additive attention influenced by the GRU hidden state. The vector $\bm {w}_{e} \in \PazoBB {R}^{d}$, and matrices $\bm {W}^{k}\in \PazoBB {R}^{d \times d}$ and $\bm {W}^{q} \in \PazoBB {R}^{2d \times 2d}$ are parameters of the BiGRU. The vector $\bm {h}_{j-1}$ is the hidden state from the BiGRU in GMGRU at previous position $j-1$. For combination function, BiDAF concatenates bidirectional attention information from both the key-aware query vector $\bm {a}_{ij}$ and a similarly defined query-aware key vector $\bm {a}^{\prime }$. GMGRU uses simple concatenation for $f_c$.\relax }}{30}{table.caption.19}
\contentsline {table}{\numberline {5.3}{\ignorespaces Input options for annotating and forecasting tasks based on CON and HGRU skeletons.\relax }}{31}{table.caption.20}
\contentsline {table}{\numberline {5.4}{\ignorespaces Main results on categorizing client codes, in terms of macro $\text {F}_{1}$, and $\text {F}_{1}$ for each client code. Our model $\mathcal {C}_C$ uses final dialogue vector $H_{n}$ and current utterance vector $v_{n}$ as input of MLP for final prediction. We found that predicting using $\text {MLP}(H_{n})+\text {MLP}(v_{n})$ performs better than just $\text {MLP}({H_{n}})$.\relax }}{33}{table.caption.21}
\contentsline {table}{\numberline {5.5}{\ignorespaces Main results on categorizing therapist codes, in terms of macro $\text {F}_{1}$, and $\text {F}_{1}$ for each therapist code. Models are the same as Table \nobreakspace {}\ref {tbl:main_rst_c_categorizing}, but tuned for therapist codes. For the two grouped MISC set \leavevmode {\color {mdgreen}\textsc {Mia}}\xspace and \leavevmode {\color {mdgreen}\textsc {Min}}\xspace , their results are not reported in the original work due to different setting.\relax }}{34}{table.caption.22}
\contentsline {table}{\numberline {5.6}{\ignorespaces Main results on forecasting client codes, in terms of $\text {F}_{1}$ for \leavevmode {\color {mdgreen}\textsc {St}}\xspace , \leavevmode {\color {mdgreen}\textsc {Ct}}\xspace on dev set, and macro $\text {F}_{1}$, and $\text {F}_{1}$ for each client code on the test set.\relax }}{35}{table.caption.23}
\contentsline {table}{\numberline {5.7}{\ignorespaces Main results on forecasting therapist codes, in terms of Recall@3, macro $\text {F}_{1}$, and $\text {F}_{1}$ for each label on test set\relax }}{35}{table.caption.24}
\contentsline {table}{\numberline {5.8}{\ignorespaces Categorization of \leavevmode {\color {mdgreen}\textsc {Ct}}\xspace /\leavevmode {\color {mdgreen}\textsc {St}}\xspace confusions.The two numbers in the brackets are the count of errors for predicting \leavevmode {\color {mdgreen}\textsc {Ct}}\xspace as \leavevmode {\color {mdgreen}\textsc {St}}\xspace and vice versa. We exampled 100 examples for each case.\relax }}{37}{table.caption.26}
\contentsline {table}{\numberline {5.9}{\ignorespaces Ablation study on categorizing client code. $*$ is our best model $\mathcal {C}_{C}$. All ablation is based on it. The symbol $+$ means adding a component to it. The default window size is 8 for our ablation models in the word attention and sentence attention parts.\relax }}{39}{table.caption.28}
\contentsline {table}{\numberline {5.10}{\ignorespaces Ablation study on categorizing therapist codes, $*$ is our proposed model $\mathcal {C}_{T}$. $\setminus $ means substituting and $-$ means removing that component. Here, we only report the important \leavevmode {\color {mdgreen}\textsc {Rec}}\xspace , \leavevmode {\color {mdgreen}\textsc {Res}}\xspace labels for guiding, and the \leavevmode {\color {mdgreen}\textsc {Min}}\xspace label for warning a therapist. \relax }}{39}{table.caption.29}
\contentsline {table}{\numberline {6.1}{\ignorespaces Summary of characteristics of \textsc {SG-dst}\xspace \textsc {MultiWOZ 2.2}\xspace datasets, in domain diversity, function overlap, data collecting methods\relax }}{44}{table.caption.31}
\contentsline {table}{\numberline {6.2}{\ignorespaces Schema description input used for different tasks to compare {\it Dual-Encoder}\xspace , {\it Cross-Encoder}\xspace , and {\it Fusion-Encoder}\xspace . In the appendix\nobreakspace {}\ref {ssec:com-desc}, we also studies other compositions of description input. We found that service description will not help for \leavevmode {\color {black}\textsc {Intent}}\xspace , \leavevmode {\color {black}\textsc {Req}}\xspace and\nobreakspace {}\leavevmode {\color {black}\textsc {Cat}}\xspace tasks, while the impact on \leavevmode {\color {black}\textsc {NonCat}}\xspace \nobreakspace {}task also varies from \textsc {SG-dst}\xspace \nobreakspace {}and\nobreakspace {}\textsc {MultiWOZ 2.2}\xspace \nobreakspace {}dataset.\relax }}{49}{table.caption.33}
\contentsline {table}{\numberline {6.3}{\ignorespaces Test set results on \textsc {SG-dst}\xspace and \textsc {MultiWOZ 2.2}\xspace . The {\it Dual-Encoder}\xspace model is a re-implementation of official DSTC8 baseline from \citet {rastogi2019towards}. Other models are trained with the architecture described in our paper.\relax }}{49}{table.caption.34}
\contentsline {table}{\numberline {6.4}{\ignorespaces Relative performance improvement of different supplementary training on \textsc {SG-dst}\xspace \nobreakspace {}and \textsc {MultiWOZ 2.2}\xspace \nobreakspace {}dataset\relax }}{50}{table.caption.35}
\contentsline {table}{\numberline {6.5}{\ignorespaces Relative performance improvement of different supplementary training on \textsc {SG-dst}\xspace \nobreakspace {}and \textsc {MultiWOZ 2.2}\xspace \nobreakspace {}dataset\relax }}{50}{table.caption.36}
\contentsline {table}{\numberline {6.6}{\ignorespaces Homogeneous evaluation results of different description style on \textsc {SG-dst}\xspace dataset and \textsc {MultiWOZ 2.2}\xspace datasets. The middle horizontal line separate the two name-based descriptions and two rich descriptions in our settings. All numbers in the table are mixed performance including both seen and unseen services.\relax }}{53}{table.caption.37}
\contentsline {table}{\numberline {6.7}{\ignorespaces Performance changes when using BERT finetuned on SQuAD2 dataset to further finetuning on our \leavevmode {\color {black}\textsc {NonCat}}\xspace \nobreakspace {}task. \relax }}{55}{table.caption.38}
\contentsline {table}{\numberline {6.8}{\ignorespaces Results on unseen service with heterogeneous description styles on \textsc {SG-dst}\xspace dataset. More results and qualitative analysis are in the appendix\nobreakspace {}\ref {ssec:more-desc-results}\relax }}{56}{table.caption.39}
