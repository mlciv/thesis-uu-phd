The design and implementation of broad-coverage and linguistically
motivated meaning representation frameworks for natural language is
attracting growing attention in recent years. With the advent of deep
neural network-based machine learning techniques, we have made
significant progress to automatically parse sentences intro structured
meaning
representation~\citep{Oep:Kuh:Miy:14,Oep:Kuh:Miy:15,May:2016wc,hershcovich-etal-2019-semeval}. Moreover,
the differences between various representation frameworks has a
significant impact on the design and performance of the parsing
systems.

Due to the abstract nature of semantics, there is a diverse set of
meaning representation frameworks in the
literature~\citep{abend2017state}. In some application scenario,
tasks-specific formal representations such as database queries,
arithmetic formula also been proposed.  However, primarily the study
in computational semantics focuses on frameworks that are
theoretically grounded on formal semantic theories, and sometimes also
with assumptions on underlying syntactic structures. In this chapter,
we mainly studied parsing graph-based symbolic representation that
inspired by computational semantics, including three broad-coverage
meaning representations~(DM, PSD, AMR) and an application-specific
representation TOP.

Anchoring is crucial in graph-based representation parsing. Training a
statistical parser typically starts with a conjectured alignment
between tokens/spans and the semantic graph nodes to help to factorize
the supervision of graph structure into nodes and edges. In this
chapter, with evidence from previous research on AMR
alignments~\citep{Pourdamghani:2014aligning,Flanigan:2014vc,Wang:2017vt,chen2017unsupervised,szubert2018structured,lyu2018amr},
we propose a uniform handling of three meaning representations~(DM,
PSD, and AMR)~into a new group referred to as the
\textbf{lexical-anchoring} MRs. It supports both explicit and implicit
anchoring of semantic concepts to tokens.  We also studied the parsing
on the other two symbolic representations~(UCCA and TOP), belonging to
the group of \textbf{phrasal-anchoring} MRs where the semantic
concepts are anchored to phrases as well.

To support the simplified taxonomy, we named our parser as
LAPA~({\textbf{L}exical-\textbf{A}nchoring and
  \textbf{P}hrasal-\textbf{A}nchoring)\footnote{The code is available
    online at \url{https://github.com/utahnlp/lapa-mrp}}. By
  leveraging the linguistic knowledge about the anchoring analysis, we
  proposed two seperate models for each anchoring type based on
  independent factorization. For lexical-anchoring, we proposed a
  graph-based parsing framework with a latent-alignment mechanism to
  support both explicit and implicit lexicon anchoring. According to
  official evaluation results, our submission ranked 1st in the AMR
  subtask, 6th on PSD, and 7th on DM respectively, among 16
  participating teams. For phrasal-anchoring, we proposed a CKY-based
  constituent tree parsing algorithm to resolve the anchor in UCCA and
  TOP. Our post-evaluation submission for MRP 2019 task ranked 5th on
  UCCA. Furthermore, we show that the same unified CKY-based model can
  be easily used to parsing an application-specific dialogue
  representation TOP, which outperforms serveral baselines in TOP
  parsing.
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../thesis-main.ltx"
%%% End:
