The design and implementation of broad coverage and linguistically
motivated meaning representation frameworks for natural language is
attracting growing attention in recent years. With the advent of deep
neural network-based machine learning techniques, we have made
significant progress to automatically parse sentences intro structured
meaning
representation~\citep{Oep:Kuh:Miy:14,Oep:Kuh:Miy:15,May:2016wc,hershcovich-etal-2019-semeval}. Moreover,
the difference between various representation frameworks has a
significant impact on the design and performance of the parsing
systems.

Due to the abstract nature of semantics, there is a diverse set of
meaning representation frameworks in the
literature~\citep{abend2017state}. In some application scenarios,
tasks-specific formal representations such as database queries,
the arithmetic formula has also been proposed. However, primarily the study
in computational semantics focuses on frameworks that are
theoretically grounded on formal semantic theories, and sometimes also
with assumptions on underlying syntactic structures. In this chapter,
we mainly studied parsing graph-based symbolic representations that
inspired by computational semantics, including three broad-coverage
meaning representations~(DM, PSD, AMR) and an application-specific
representation TOP.

Anchoring is crucial in graph-based representation parsing. Training a
statistical parser typically starts with a conjectured alignment
between tokens~(or spans) and the semantic graph nodes, to help to
factorize the supervision of graph structure into nodes and edges. In
this chapter, with evidence from previous research on AMR
alignments~\citep{Pourdamghani:2014aligning,Flanigan:2014vc,Wang:2017vt,chen2017unsupervised,szubert2018structured,lyu2018amr},
we propose a uniform handling of three meaning representations~(DM,
PSD, and AMR)~into a new group referred to as the
\textbf{lexical-anchoring} representations. It supports both explicit
and implicit anchoring of semantic concepts to tokens. We also studied
the parsing on the other two symbolic representations~(UCCA and TOP),
belonging to the group of \textbf{phrasal-anchoring} representations
where the semantic concepts are anchored to phrases as well.


To support the simplified taxonomy, we named our parser as
LAPA~({\textbf{L}exical-\textbf{A}nchoring and
  \textbf{P}hrasal-\textbf{A}nchoring)\footnote{The code is available
    online at \url{https://github.com/utahnlp/lapa-mrp}}. By
  leveraging the linguistic knowledge about the anchoring analysis, we
  proposed two separate models for each anchoring type based on
  independent factorization. For lexical anchoring, we proposed a
  graph-based parsing framework with a latent-alignment mechanism to
  support both explicit and implicit lexicon anchoring. According to
  official evaluation results, our submission ranked 1st in the AMR
  subtask, 6th on PSD, and 7th on DM, respectively, among 16
  participating teams. For phrasal-anchoring, we proposed a CKY-based
  constituent tree parsing algorithm to resolve the anchor in UCCA and
  TOP. Our post-evaluation submission for MRP 2019 task ranked 5th on
  UCCA. Furthermore, we show that the same unified CKY-based model can
  be easily used to parse an application-specific dialogue
  representation TOP, which outperforms several baselines in TOP
  parsing. Most parts of this chaper is published in our
  paper~\cite{cao2019amazon}.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../dissertation-main.ltx"
%%% End:
