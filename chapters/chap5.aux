\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{burke2004emerging,martins2009review,lundahl2010meta}
\citation{Schwalbe2014}
\citation{stolcke2000dialogue,jurafsky2018speech}
\citation{miller2003manual}
\citation{xiao2016behavioral}
\citation{tanana2016comparison,xiao2016behavioral,perez2017predicting}
\@writefile{toc}{\contentsline {chapter}{\numberline {5.}\hyphenpenalty =10000\exhyphenpenalty =10000\relax \linepenalty =0 \uppercase {Modeling on Sentence-Anchoring for Dialog in Therapy}\global \uuthesis@needtocspacetrue }{25}{chapter.5}}
\@writefile{toc}{\ifuuthesis@needtocspace \vspace {\uuthesis@chaptersectionspace } \fi \global \uuthesis@needtocspacefalse }
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Background and Motivation}{25}{section.5.1}}
\newlabel{sec:snt:background}{{5.1}{25}{Modeling on Sentence-Anchoring for Dialog in Therapy}{section.5.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces  An example of ongoing therapy session\relax }}{26}{table.caption.18}}
\newlabel{tbl:example}{{5.1}{26}{An example of ongoing therapy session\relax }{table.caption.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Task Definitions}{26}{section.5.2}}
\newlabel{sec:snt:task}{{5.2}{26}{Modeling on Sentence-Anchoring for Dialog in Therapy}{section.5.2}{}}
\citation{schatzmann2005quantitative,ubuntu,DSTC7}
\citation{imel2017technology}
\citation{zhang2018conversations}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Models for MISC Prediction}{27}{section.5.3}}
\newlabel{sec:snt:devices}{{5.3}{27}{Modeling on Sentence-Anchoring for Dialog in Therapy}{section.5.3}{}}
\citation{li2015hierarchical,sordoni2015hierarchical,serban2016building}
\citation{galassi2019attention}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Encoding Dialogue}{28}{subsection.5.3.1}}
\newlabel{ssec:dialog_rep}{{5.3.1}{28}{Modeling on Sentence-Anchoring for Dialog in Therapy}{subsection.5.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Word-level Attention}{28}{subsection.5.3.2}}
\newlabel{ssec:word_att}{{5.3.2}{28}{Modeling on Sentence-Anchoring for Dialog in Therapy}{subsection.5.3.2}{}}
\citation{bidaf}
\citation{wang2017gated}
\newlabel{eq:att_sum}{{5.1}{29}{Modeling on Sentence-Anchoring for Dialog in Therapy}{equation.5.3.1}{}}
\newlabel{eq:att_weight}{{5.2}{29}{Modeling on Sentence-Anchoring for Dialog in Therapy}{equation.5.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Utterance-level Attention}{29}{subsection.5.3.3}}
\newlabel{ssec:sentence_att}{{5.3.3}{29}{Modeling on Sentence-Anchoring for Dialog in Therapy}{subsection.5.3.3}{}}
\citation{NIPS2017_7181}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces  Summary of word attention mechanisms. We simplify BiDAF with multiplicative attention between word pairs for $f_{m}$, while GMGRU uses additive attention influenced by the GRU hidden state. The vector $\bm  {w}_{e} \in \PazoBB  {R}^{d}$, and matrices $\bm  {W}^{k}\in \PazoBB  {R}^{d \times d}$ and $\bm  {W}^{q} \in \PazoBB  {R}^{2d \times 2d}$ are parameters of the BiGRU. The vector $\bm  {h}_{j-1}$ is the hidden state from the BiGRU in GMGRU at previous position $j-1$. For combination function, BiDAF concatenates bidirectional attention information from both the key-aware query vector $\bm  {a}_{ij}$ and a similarly defined query-aware key vector $\bm  {a}^{\prime }$. GMGRU uses simple concatenation for $f_c$.\relax }}{30}{table.caption.19}}
\newlabel{tbl:word_att}{{5.2}{30}{Summary of word attention mechanisms. We simplify BiDAF with multiplicative attention between word pairs for $f_{m}$, while GMGRU uses additive attention influenced by the GRU hidden state. The vector $\bm {w}_{e} \in \mathbb {R}^{d}$, and matrices $\bm {W}^{k}\in \mathbb {R}^{d \times d}$ and $\bm {W}^{q} \in \mathbb {R}^{2d \times 2d}$ are parameters of the BiGRU. The vector $\bm {h}_{j-1}$ is the hidden state from the BiGRU in GMGRU at previous position $j-1$. For combination function, BiDAF concatenates bidirectional attention information from both the key-aware query vector $\ba _{ij}$ and a similarly defined query-aware key vector $\ba ^{\prime }$. GMGRU uses simple concatenation for $f_c$.\relax }{table.caption.19}{}}
\newlabel{eq:multihead_attention}{{5.4}{30}{Modeling on Sentence-Anchoring for Dialog in Therapy}{equation.5.3.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces  Input options for annotating and forecasting tasks based on CON and HGRU skeletons.\relax }}{31}{table.caption.20}}
\newlabel{tbl:inference_options}{{5.3}{31}{Input options for annotating and forecasting tasks based on CON and HGRU skeletons.\relax }{table.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}Predicting and Training}{31}{subsection.5.3.4}}
\newlabel{ssec:inference_and_training}{{5.3.4}{31}{Modeling on Sentence-Anchoring for Dialog in Therapy}{subsection.5.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.5}Addressing Label Imbalance}{31}{subsection.5.3.5}}
\newlabel{ssec:focal_loss}{{5.3.5}{31}{Modeling on Sentence-Anchoring for Dialog in Therapy}{subsection.5.3.5}{}}
\citation{lin2017focal}
\citation{roy2014brief}
\citation{baer2009agency}
\citation{tollison2008questions,neighbors2012randomized,lee2013indicated,lee2014randomized}
\citation{atkins2014scaling}
\citation{can2015dialog,tanana2016comparison}
\citation{xiao2016behavioral}
\citation{spacy2}
\citation{pennington2014glove}
\citation{Peters:2018}
\newlabel{eq:focal}{{5.5}{32}{Modeling on Sentence-Anchoring for Dialog in Therapy}{equation.5.3.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Experiments}{32}{section.5.4}}
\newlabel{sec:snt:experiments}{{5.4}{32}{Modeling on Sentence-Anchoring for Dialog in Therapy}{section.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Preprocessing and Model Setup}{32}{subsection.5.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Results}{32}{subsection.5.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Best Models}{32}{subsection.5.4.3}}
\newlabel{ssec:models}{{5.4.3}{32}{Modeling on Sentence-Anchoring for Dialog in Therapy}{subsection.5.4.3}{}}
\citation{xiao2016behavioral}
\citation{can2015dialog}
\citation{tanana2016comparison}
\citation{xiao2016behavioral}
\citation{can2015dialog}
\citation{tanana2016comparison}
\citation{xiao2016behavioral}
\citation{can2015dialog}
\citation{tanana2016comparison}
\citation{xiao2016behavioral}
\citation{perez2017predicting,gibson2017attention}
\citation{xiao2016behavioral}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces  Main results on categorizing client codes, in terms of macro $\text  {F}_{1}$, and $\text  {F}_{1}$ for each client code. Our model $\mathcal  {C}_C$ uses final dialogue vector $H_{n}$ and current utterance vector $v_{n}$ as input of MLP for final prediction. We found that predicting using $\text  {MLP}(H_{n})+\text  {MLP}(v_{n})$ performs better than just $\text  {MLP}({H_{n}})$.\relax }}{33}{table.caption.21}}
\newlabel{tbl:main_rst_c_categorizing}{{5.4}{33}{Main results on categorizing client codes, in terms of macro $\text {F}_{1}$, and $\text {F}_{1}$ for each client code. Our model $\mathcal {C}_C$ uses final dialogue vector $H_{n}$ and current utterance vector $v_{n}$ as input of MLP for final prediction. We found that predicting using $\text {MLP}(H_{n})+\text {MLP}(v_{n})$ performs better than just $\text {MLP}({H_{n}})$.\relax }{table.caption.21}{}}
\citation{can2015dialog}
\citation{tanana2016comparison}
\citation{huang2018modeling}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces  Main results on categorizing therapist codes, in terms of macro $\text  {F}_{1}$, and $\text  {F}_{1}$ for each therapist code. Models are the same as Table \nobreakspace  {}\ref  {tbl:main_rst_c_categorizing}, but tuned for therapist codes. For the two grouped MISC set \leavevmode {\color  {mdgreen}\textsc  {Mia}}\xspace  and \leavevmode {\color  {mdgreen}\textsc  {Min}}\xspace  , their results are not reported in the original work due to different setting.\relax }}{34}{table.caption.22}}
\newlabel{tbl:main_rst_t_categorizing}{{5.5}{34}{Main results on categorizing therapist codes, in terms of macro $\text {F}_{1}$, and $\text {F}_{1}$ for each therapist code. Models are the same as Table ~\ref {tbl:main_rst_c_categorizing}, but tuned for therapist codes. For the two grouped MISC set \MIA and \MIN , their results are not reported in the original work due to different setting.\relax }{table.caption.22}{}}
\citation{DSTC7}
\@writefile{lot}{\contentsline {table}{\numberline {5.6}{\ignorespaces  Main results on forecasting client codes, in terms of $\text  {F}_{1}$ for \leavevmode {\color  {mdgreen}\textsc  {St}}\xspace  , \leavevmode {\color  {mdgreen}\textsc  {Ct}}\xspace  on dev set, and macro $\text  {F}_{1}$, and $\text  {F}_{1}$ for each client code on the test set.\relax }}{35}{table.caption.23}}
\newlabel{tbl:main_rst_forecast:client}{{5.6}{35}{Main results on forecasting client codes, in terms of $\text {F}_{1}$ for \SUSTAIN , \CHANGE on dev set, and macro $\text {F}_{1}$, and $\text {F}_{1}$ for each client code on the test set.\relax }{table.caption.23}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.7}{\ignorespaces  Main results on forecasting therapist codes, in terms of Recall@3, macro $\text  {F}_{1}$, and $\text  {F}_{1}$ for each label on test set\relax }}{35}{table.caption.24}}
\newlabel{tbl:main_rst_forecast:therapist}{{5.7}{35}{Main results on forecasting therapist codes, in terms of Recall@3, macro $\text {F}_{1}$, and $\text {F}_{1}$ for each label on test set\relax }{table.caption.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Analysis and Ablations}{36}{section.5.5}}
\newlabel{sec:snt:analysis}{{5.5}{36}{Modeling on Sentence-Anchoring for Dialog in Therapy}{section.5.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Label Confusion and Error Breakdown}{36}{subsection.5.5.1}}
\newlabel{ssec:label_confusion}{{5.5.1}{36}{Modeling on Sentence-Anchoring for Dialog in Therapy}{subsection.5.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces  Confusion matrix for categorizing client codes, normalized by row.\relax }}{36}{figure.caption.25}}
\newlabel{fig:categorizing_confusion_client}{{5.1}{36}{Confusion matrix for categorizing client codes, normalized by row.\relax }{figure.caption.25}{}}
\citation{xiao2016behavioral}
\@writefile{lot}{\contentsline {table}{\numberline {5.8}{\ignorespaces Categorization of \leavevmode {\color  {mdgreen}\textsc  {Ct}}\xspace  /\leavevmode {\color  {mdgreen}\textsc  {St}}\xspace  confusions.The two numbers in the brackets are the count of errors for predicting \leavevmode {\color  {mdgreen}\textsc  {Ct}}\xspace  as \leavevmode {\color  {mdgreen}\textsc  {St}}\xspace  and vice versa. We exampled 100 examples for each case.\relax }}{37}{table.caption.26}}
\newlabel{tbl:c_client_errors}{{5.8}{37}{Categorization of \CHANGE /\SUSTAIN confusions.The two numbers in the brackets are the count of errors for predicting \CHANGE as \SUSTAIN and vice versa. We exampled 100 examples for each case.\relax }{table.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces  Confusion matrix for categorizing therapist codes, normalized by row.\relax }}{37}{figure.caption.27}}
\newlabel{fig:categorizing_confusion_therapist}{{5.2}{37}{Confusion matrix for categorizing therapist codes, normalized by row.\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}How Context and Attention Help?}{38}{subsection.5.5.2}}
\newlabel{ssec:abl_context_attention}{{5.5.2}{38}{Modeling on Sentence-Anchoring for Dialog in Therapy}{subsection.5.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.9}{\ignorespaces  Ablation study on categorizing client code. $*$ is our best model $\mathcal  {C}_{C}$. All ablation is based on it. The symbol $+$ means adding a component to it. The default window size is 8 for our ablation models in the word attention and sentence attention parts.\relax }}{39}{table.caption.28}}
\newlabel{tbl:rst_cxt_client}{{5.9}{39}{Ablation study on categorizing client code. $*$ is our best model $\mathcal {C}_{C}$. All ablation is based on it. The symbol $+$ means adding a component to it. The default window size is 8 for our ablation models in the word attention and sentence attention parts.\relax }{table.caption.28}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.10}{\ignorespaces  Ablation study on categorizing therapist codes, $*$ is our proposed model $\mathcal  {C}_{T}$. $\setminus $ means substituting and $-$ means removing that component. Here, we only report the important \leavevmode {\color  {mdgreen}\textsc  {Rec}}\xspace  , \leavevmode {\color  {mdgreen}\textsc  {Res}}\xspace  labels for guiding, and the \leavevmode {\color  {mdgreen}\textsc  {Min}}\xspace  label for warning a therapist. \relax }}{39}{table.caption.29}}
\newlabel{tbl:rst_cxt_therapist}{{5.10}{39}{Ablation study on categorizing therapist codes, $*$ is our proposed model $\mathcal {C}_{T}$. $\setminus $ means substituting and $-$ means removing that component. Here, we only report the important \REC , \RES labels for guiding, and the \MIN label for warning a therapist. \relax }{table.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}Can We Suggest Empathetic Responses?}{39}{subsection.5.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Conclusion}{40}{section.5.6}}
\@setckpt{chapters/chap5}{
\setcounter{page}{41}
\setcounter{equation}{5}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{4}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{figure}{2}
\setcounter{table}{10}
\setcounter{oldchapter}{0}
\setcounter{oldtocdepth}{0}
\setcounter{section}{6}
\setcounter{subsection}{0}
\setcounter{paragraph}{0}
\setcounter{subsubsection}{0}
\setcounter{parentequation}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{AM@survey}{0}
\setcounter{vrcnt}{0}
\setcounter{lstnumber}{1}
\setcounter{float@type}{16}
\setcounter{algorithm}{0}
\setcounter{ALC@unique}{0}
\setcounter{ALC@line}{0}
\setcounter{ALC@rem}{0}
\setcounter{ALC@depth}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{KVtest}{0}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{lotdepth}{1}
\setcounter{NAT@ctr}{0}
\setcounter{Item}{13}
\setcounter{Hfootnote}{5}
\setcounter{bookmark@seq@number}{87}
\setcounter{lstlisting}{0}
\setcounter{section@level}{0}
}
